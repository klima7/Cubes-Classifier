{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10019 files belonging to 10 classes.\n",
      "Found 353 files belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  'data/dataset/',\n",
    "  label_mode='categorical',\n",
    "  shuffle=True,\n",
    "  seed=42,\n",
    "  image_size=(32, 32),\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  'data/test_dataset/',\n",
    "  label_mode='categorical',\n",
    "  shuffle=True,\n",
    "  seed=42,\n",
    "  image_size=(32, 32),\n",
    ")\n",
    "\n",
    "def transform_dataset(x, y):\n",
    "  # gray = cv2.cvtColor(x, cv2.COLOR_RGB2GRAY)\n",
    "  print(x.shape)\n",
    "  print(y)\n",
    "  return x\n",
    "\n",
    "# train_ds = train_ds.map(transform_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    layers.Input(shape=(None, None, 3)),\n",
    "    layers.Resizing(16, 16),\n",
    "    layers.Rescaling(1./255),\n",
    "    # layers.RandomBrightness(0.2, value_range=(0, 1)),\n",
    "    layers.RandomFlip('horizontal'),\n",
    "    # layers.RandomRotation(0.2),\n",
    "    # layers.RandomZoom(),\n",
    "    # layers.RandomTranslation(),\n",
    "    # layers.RandomContrast(),\n",
    "    # layers.RandomCrop()\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(10, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resizing_1 (Resizing)       (None, 16, 16, 3)         0         \n",
      "                                                                 \n",
      " rescaling_1 (Rescaling)     (None, 16, 16, 3)         0         \n",
      "                                                                 \n",
      " random_flip_1 (RandomFlip)  (None, 16, 16, 3)         0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 14, 14, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 7, 7, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 5, 5, 64)          18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 2, 2, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,250\n",
      "Trainable params: 38,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "314/314 [==============================] - 10s 32ms/step - loss: 0.2389 - accuracy: 0.9220 - val_loss: 8.9055 - val_accuracy: 0.3314\n",
      "Epoch 2/40\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 0.2588 - accuracy: 0.9202 - val_loss: 8.6488 - val_accuracy: 0.3144\n",
      "Epoch 3/40\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 0.2447 - accuracy: 0.9215 - val_loss: 8.8688 - val_accuracy: 0.3286\n",
      "Epoch 4/40\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 0.2488 - accuracy: 0.9197 - val_loss: 9.4918 - val_accuracy: 0.2975\n",
      "Epoch 5/40\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 0.2446 - accuracy: 0.9227 - val_loss: 8.6627 - val_accuracy: 0.3144\n",
      "Epoch 6/40\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 0.2393 - accuracy: 0.9264 - val_loss: 9.3736 - val_accuracy: 0.2861\n",
      "Epoch 7/40\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 0.2306 - accuracy: 0.9283 - val_loss: 8.2966 - val_accuracy: 0.3088\n",
      "Epoch 8/40\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 0.2493 - accuracy: 0.9215 - val_loss: 9.5386 - val_accuracy: 0.2861\n",
      "Epoch 9/40\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 0.2404 - accuracy: 0.9211 - val_loss: 9.4094 - val_accuracy: 0.3003\n",
      "Epoch 10/40\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 0.2054 - accuracy: 0.9352 - val_loss: 9.1835 - val_accuracy: 0.3088\n",
      "Epoch 11/40\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 0.2418 - accuracy: 0.9226 - val_loss: 9.2116 - val_accuracy: 0.3229\n",
      "Epoch 12/40\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 0.2191 - accuracy: 0.9312 - val_loss: 9.9416 - val_accuracy: 0.3116\n",
      "Epoch 13/40\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 0.2176 - accuracy: 0.9305 - val_loss: 9.7000 - val_accuracy: 0.3598\n",
      "Epoch 14/40\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 0.2269 - accuracy: 0.9267 - val_loss: 9.2919 - val_accuracy: 0.3003\n",
      "Epoch 15/40\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 0.1980 - accuracy: 0.9368 - val_loss: 8.8335 - val_accuracy: 0.3484\n",
      "Epoch 16/40\n",
      "314/314 [==============================] - 11s 35ms/step - loss: 0.2014 - accuracy: 0.9356 - val_loss: 9.9880 - val_accuracy: 0.3286\n",
      "Epoch 17/40\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 0.2146 - accuracy: 0.9340 - val_loss: 10.3354 - val_accuracy: 0.2748\n",
      "Epoch 18/40\n",
      "314/314 [==============================] - 11s 35ms/step - loss: 0.1970 - accuracy: 0.9352 - val_loss: 9.7870 - val_accuracy: 0.3258\n",
      "Epoch 19/40\n",
      "314/314 [==============================] - 11s 33ms/step - loss: 0.2152 - accuracy: 0.9334 - val_loss: 8.7404 - val_accuracy: 0.3201\n",
      "Epoch 20/40\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 0.1739 - accuracy: 0.9452 - val_loss: 10.7194 - val_accuracy: 0.3059\n",
      "Epoch 21/40\n",
      " 37/314 [==>...........................] - ETA: 9s - loss: 0.1831 - accuracy: 0.9417"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, validation_data=test_ds, epochs=40, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = zip(*test_ds)\n",
    "X = np.concatenate(X)\n",
    "y = np.concatenate(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = next(iter(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((72, 32, 32, 3), (72, 10))"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 178ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.25      0.40      0.31        10\n",
      "           4       0.75      0.43      0.55         7\n",
      "           5       0.56      0.75      0.64        12\n",
      "           6       0.00      0.00      0.00         3\n",
      "           7       0.00      0.00      0.00        11\n",
      "           8       0.29      0.33      0.31         6\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.34        53\n",
      "   macro avg       0.18      0.19      0.18        53\n",
      "weighted avg       0.31      0.34      0.31        53\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lukasz\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Lukasz\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Lukasz\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "X, y = zip(*test_ds)\n",
    "X = np.concatenate(X)\n",
    "y = np.concatenate(y)\n",
    "\n",
    "predictions = model.predict(X)\n",
    "report = classification_report(np.argmax(y, axis=1), np.argmax(predictions, axis=1))\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f14c42d44d5aca93a07ae152a604bc05c55a838d5339618e42b4c4346ef3b75c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
